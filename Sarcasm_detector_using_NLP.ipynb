{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXhmw53aJD8pxeLsF7vl6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnweshaAdhikari/Sarcasm-detector-using-NLP./blob/main/Sarcasm_detector_using_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sentences = [\n",
        "    \"Hi I am a person\",\n",
        "    \"A person who wants to have a little happiness\"]\n",
        "\n",
        "token_sentences = [\n",
        "    \"Is it okay to be just a person?\",\n",
        "    \"Maybe I should just be a person\"]\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"*oov*\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)\n",
        "text_to_sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(text_to_sequences, padding=\"post\")\n",
        "print(text_to_sequences)\n",
        "print(padded)\n",
        "test_token = tokenizer.texts_to_sequences(token_sentences)\n",
        "print(test_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQq74tvr_fVI",
        "outputId": "6018f85b-4390-42c2-95a8-5ae4c47bece8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'*oov*': 1, 'a': 2, 'person': 3, 'hi': 4, 'i': 5, 'am': 6, 'who': 7, 'wants': 8, 'to': 9, 'have': 10, 'little': 11, 'happiness': 12}\n",
            "[[4, 5, 6, 2, 3], [2, 3, 7, 8, 9, 10, 2, 11, 12]]\n",
            "[[ 4  5  6  2  3  0  0  0  0]\n",
            " [ 2  3  7  8  9 10  2 11 12]]\n",
            "[[1, 1, 1, 9, 1, 1, 2, 3], [1, 5, 1, 1, 1, 2, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset by Rishabh Mishra\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/learning-datasets/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6ApEKl4MjH4",
        "outputId": "cc33a2d0-3549-453b-a14c-84a8b5916bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-22 21:37:27--  https://storage.googleapis.com/learning-datasets/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.115.207, 172.253.122.207, 172.253.63.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.115.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-05-22 21:37:27 (152 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=30000\n",
        "embedding_dim=16\n",
        "max_length=100\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '*oov*'"
      ],
      "metadata": {
        "id": "V_MBKfuxBNs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Looking at articles and deciding if they are sarcastic or not\n",
        "\n",
        "# Tokenization\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"/tmp/sarcasm.json\",'r') as file:\n",
        "  datastore = json.load(file)\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "for item in datastore:\n",
        "  sentences.append(item['headline'])\n",
        "  labels.append(item['is_sarcastic'])\n",
        "  urls.append(item['article_link'])\n",
        "\n",
        "training_size = 20000\n",
        "training_sentences = sentences[0:training_size]\n",
        "test_sentences = sentences[training_size:]\n",
        "training_labels = labels[0:training_size]\n",
        "test_labels = labels[training_size:]\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"*oov*\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_training = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "padded_test = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "#print(word_index)\n",
        "print(padded_training[0])\n",
        "print(padded_training.shape)\n",
        "\n",
        "print(padded_test[0])\n",
        "print(padded_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Mcy5CkTLc3W",
        "outputId": "87c39816-e602-412c-ca53-fdc532962cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  328 12776   799  3405  2404    47   389  2214 12777     6  2614  8863\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "(20000, 100)\n",
            "[17706  1100  6663  9423    30 11505  2439     5   519   109     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "(6709, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6wtOFzJ0Pg-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "padded_training = np.array(padded_training)\n",
        "training_labels = np.array(training_labels)\n",
        "padded_testing = np.array(padded_test)\n",
        "test_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "9_u8RkccCDjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pv2UtkXDmnH",
        "outputId": "c9e40fef-6fdb-4ec5-9f1c-3b5978efc3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_18 (Embedding)    (None, 100, 16)           480000    \n",
            "                                                                 \n",
            " global_average_pooling1d_1  (None, 16)                0         \n",
            " 2 (GlobalAveragePooling1D)                                      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 24)                408       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 480433 (1.83 MB)\n",
            "Trainable params: 480433 (1.83 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Training and Testing\n",
        "\n",
        "num_epoch = 30\n",
        "history = model.fit(padded_training, training_labels,epochs = num_epoch, validation_data = (padded_test, test_labels), verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qermy2OQBlNP",
        "outputId": "abba4f9a-5a77-4b7a-b6a4-7561d71cc0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "625/625 - 8s - loss: 0.6557 - accuracy: 0.5923 - val_loss: 0.5480 - val_accuracy: 0.8128 - 8s/epoch - 13ms/step\n",
            "Epoch 2/30\n",
            "625/625 - 6s - loss: 0.4009 - accuracy: 0.8481 - val_loss: 0.3725 - val_accuracy: 0.8462 - 6s/epoch - 9ms/step\n",
            "Epoch 3/30\n",
            "625/625 - 7s - loss: 0.2743 - accuracy: 0.8964 - val_loss: 0.3439 - val_accuracy: 0.8562 - 7s/epoch - 11ms/step\n",
            "Epoch 4/30\n",
            "625/625 - 6s - loss: 0.2121 - accuracy: 0.9225 - val_loss: 0.3609 - val_accuracy: 0.8450 - 6s/epoch - 9ms/step\n",
            "Epoch 5/30\n",
            "625/625 - 7s - loss: 0.1662 - accuracy: 0.9423 - val_loss: 0.3482 - val_accuracy: 0.8557 - 7s/epoch - 11ms/step\n",
            "Epoch 6/30\n",
            "625/625 - 6s - loss: 0.1309 - accuracy: 0.9571 - val_loss: 0.3579 - val_accuracy: 0.8562 - 6s/epoch - 9ms/step\n",
            "Epoch 7/30\n",
            "625/625 - 7s - loss: 0.1036 - accuracy: 0.9665 - val_loss: 0.4020 - val_accuracy: 0.8445 - 7s/epoch - 11ms/step\n",
            "Epoch 8/30\n",
            "625/625 - 6s - loss: 0.0825 - accuracy: 0.9762 - val_loss: 0.3983 - val_accuracy: 0.8532 - 6s/epoch - 9ms/step\n",
            "Epoch 9/30\n",
            "625/625 - 7s - loss: 0.0646 - accuracy: 0.9827 - val_loss: 0.4249 - val_accuracy: 0.8505 - 7s/epoch - 12ms/step\n",
            "Epoch 10/30\n",
            "625/625 - 7s - loss: 0.0518 - accuracy: 0.9861 - val_loss: 0.4549 - val_accuracy: 0.8466 - 7s/epoch - 11ms/step\n",
            "Epoch 11/30\n",
            "625/625 - 7s - loss: 0.0397 - accuracy: 0.9908 - val_loss: 0.4891 - val_accuracy: 0.8439 - 7s/epoch - 11ms/step\n",
            "Epoch 12/30\n",
            "625/625 - 6s - loss: 0.0319 - accuracy: 0.9926 - val_loss: 0.5311 - val_accuracy: 0.8420 - 6s/epoch - 10ms/step\n",
            "Epoch 13/30\n",
            "625/625 - 6s - loss: 0.0257 - accuracy: 0.9944 - val_loss: 0.5943 - val_accuracy: 0.8378 - 6s/epoch - 10ms/step\n",
            "Epoch 14/30\n",
            "625/625 - 6s - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.6011 - val_accuracy: 0.8359 - 6s/epoch - 10ms/step\n",
            "Epoch 15/30\n",
            "625/625 - 6s - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.6952 - val_accuracy: 0.8351 - 6s/epoch - 9ms/step\n",
            "Epoch 16/30\n",
            "625/625 - 7s - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.7230 - val_accuracy: 0.8356 - 7s/epoch - 11ms/step\n",
            "Epoch 17/30\n",
            "625/625 - 6s - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.7269 - val_accuracy: 0.8290 - 6s/epoch - 9ms/step\n",
            "Epoch 18/30\n",
            "625/625 - 7s - loss: 0.0074 - accuracy: 0.9991 - val_loss: 0.7778 - val_accuracy: 0.8284 - 7s/epoch - 11ms/step\n",
            "Epoch 19/30\n",
            "625/625 - 6s - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.8419 - val_accuracy: 0.8301 - 6s/epoch - 9ms/step\n",
            "Epoch 20/30\n",
            "625/625 - 7s - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.9305 - val_accuracy: 0.8289 - 7s/epoch - 12ms/step\n",
            "Epoch 21/30\n",
            "625/625 - 6s - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.9149 - val_accuracy: 0.8265 - 6s/epoch - 9ms/step\n",
            "Epoch 22/30\n",
            "625/625 - 6s - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.9514 - val_accuracy: 0.8259 - 6s/epoch - 10ms/step\n",
            "Epoch 23/30\n",
            "625/625 - 6s - loss: 0.0027 - accuracy: 0.9995 - val_loss: 1.0304 - val_accuracy: 0.8262 - 6s/epoch - 10ms/step\n",
            "Epoch 24/30\n",
            "625/625 - 6s - loss: 0.0016 - accuracy: 0.9998 - val_loss: 1.0417 - val_accuracy: 0.8241 - 6s/epoch - 9ms/step\n",
            "Epoch 25/30\n",
            "625/625 - 7s - loss: 9.3743e-04 - accuracy: 0.9999 - val_loss: 1.0683 - val_accuracy: 0.8210 - 7s/epoch - 11ms/step\n",
            "Epoch 26/30\n",
            "625/625 - 6s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 1.1602 - val_accuracy: 0.8243 - 6s/epoch - 9ms/step\n",
            "Epoch 27/30\n",
            "625/625 - 7s - loss: 6.6410e-04 - accuracy: 0.9999 - val_loss: 1.1871 - val_accuracy: 0.8217 - 7s/epoch - 11ms/step\n",
            "Epoch 28/30\n",
            "625/625 - 6s - loss: 4.9528e-04 - accuracy: 1.0000 - val_loss: 1.2571 - val_accuracy: 0.8232 - 6s/epoch - 9ms/step\n",
            "Epoch 29/30\n",
            "625/625 - 7s - loss: 9.9138e-04 - accuracy: 0.9998 - val_loss: 1.2927 - val_accuracy: 0.8214 - 7s/epoch - 11ms/step\n",
            "Epoch 30/30\n",
            "625/625 - 6s - loss: 2.9194e-04 - accuracy: 1.0000 - val_loss: 1.5732 - val_accuracy: 0.8149 - 6s/epoch - 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Giving some sentences a 'sarcasm percentages'\n",
        "\n",
        "example_sentences = [\n",
        "    \"Oh, I am so thrilled to be this lonely in life.\",\n",
        "    \"I am going home tomorrow.\",\n",
        "    \"Of course, you truly are the symbol of cleanliness.\"\n",
        "]\n",
        "# Tokenizing\n",
        "example_sequences = tokenizer.texts_to_sequences(example_sentences)\n",
        "# Padding\n",
        "example_padded = pad_sequences(example_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "# Testing\n",
        "print(model.predict(example_padded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-DF_iPJGelu",
        "outputId": "1956599e-6f43-4be4-ad82-be82cef6e8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "[[9.113963e-09]\n",
            " [3.007744e-08]\n",
            " [9.996564e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding but with Long Short Tem Memory (LSTM)\n",
        "\n",
        "model_new = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "model_new.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model_new.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLG9U-v8L4IY",
        "outputId": "af67e3cb-f635-4172-a35e-3ae35081ca9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_19 (Embedding)    (None, 100, 16)           480000    \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirecti  (None, 100, 128)          41472     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 64)                41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 24)                1560      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 564273 (2.15 MB)\n",
            "Trainable params: 564273 (2.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Giving some sentences a 'sarcasm percentages'\n",
        "\n",
        "example_sentences = [\n",
        "    \"Oh, I am so thrilled to be this lonely in life.\",\n",
        "    \"I am going home tomorrow.\",\n",
        "    \"Of course, you truly are the symbol of cleanliness.\"\n",
        "]\n",
        "# Tokenizing\n",
        "example_sequences = tokenizer.texts_to_sequences(example_sentences)\n",
        "# Padding\n",
        "example_padded = pad_sequences(example_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "# Testing\n",
        "print(model_new.predict(example_padded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFCgKuMhNZp-",
        "outputId": "f907d71f-bea8-4667-d773-b2fa85d8290c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "[[0.49986562]\n",
            " [0.5009383 ]\n",
            " [0.50056624]]\n"
          ]
        }
      ]
    }
  ]
}